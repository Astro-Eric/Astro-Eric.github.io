[{"content":"","description":"","image":"/images/Beijing/DSC06162.jpg","permalink":"/gallery/beijing/","title":"Beijing"},{"content":"","description":"","image":"/images/California/DSC09022.jpg","permalink":"/gallery/california/","title":"California"},{"content":"\u003ch1 id=\"large-language-models-are-surjective-injective-invertible\"\u003eLarge Language Models are Surjective? Injective? Invertible?\u003c/h1\u003e\n\u003cp\u003eRecently, there have been discussions on functional properties of Transformers, the basic building block of Large Language Models (LLM) and many other generative models. \u003ca href=\"https://arxiv.org/abs/2508.19445\"\u003eMy paper\u003c/a\u003e ([1]) proves that Transformers can output anything given an appropriate input (surjective). After a few months, \u003ca href=\"https://arxiv.org/abs/2510.15511\"\u003ea followup\u003c/a\u003e ([2]) proves that LLMs always send different inputs to different outputs (injective), and hence we can invert the outputs back to inputs. With these claims in mind, wild thoughts about generative models start flowing around. Are jailbreaks fundamentally unavoidable? Are Transformers lossless compression of knowledge? Do we have no privacy when we use LLMs? Does combining the two papers imply that LLMs are bijective? In this blog, we clarify the concepts of surjectivity, injectivity and invertibility that appear in these papers and explain their true implications.\u003c/p\u003e\n\u003ch2 id=\"what-is-surjectivityinjectivityinvertibility\"\u003eWhat is Surjectivity/Injectivity/Invertibility?\u003c/h2\u003e\n\u003cp\u003eThese concepts are not hard to understand but the differences are nuanced. In the following, we will work with a function $f:\\mathcal{X}\\to\\mathcal{Y}$.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eSurjective\u003c/strong\u003e: Surjectivity means that for any $y$ from $\\mathcal{Y}$, there exists an $x$ from $\\mathcal{X}$, such that $f(x)=y$. In other words, every element in $\\mathcal{Y}$ is reachable from some input from $\\mathcal{X}$. A surjective function is also called an \u003cstrong\u003eonto\u003c/strong\u003e function.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eInjective\u003c/strong\u003e: Injectivity means that for any two different $x_1,x_2$ from $\\mathcal{X}$, the outputs $f(x_1),f(x_2)$ are also different. In other words, different elements from $\\mathcal{X}$ are mapped to different elements in $\\mathcal{Y}$. An injective function is also called a \u003cstrong\u003eone-to-one\u003c/strong\u003e function.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eInvertible\u003c/strong\u003e: Invertibility means both surjectivity and injectivity. In other words, $f$ defines a correspondence between $\\mathcal{X}$ and $\\mathcal{Y}$, such that every element in $\\mathcal{X}$ correspond to a unique element in $\\mathcal{Y}$ and vice versa. An invertible function is also called a \u003cstrong\u003ebijective\u003c/strong\u003e function. \u003cem\u003eWe can invert an output of an injective function uniquely to its input, but an injective function is not necessarily an invertible function.\u003c/em\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eLet us now look at some examples to understand their differences. We visualize three functions from two dimensional Euclidean space to itself, showing how the grids change according to the function.\u003c/p\u003e\n\u003ctable style=\"width:100%; table-layout:fixed; text-align:center;\"\u003e\n  \u003ctr\u003e\n    \u003ctd style=\"width:33%; vertical-align:top;\"\u003e\n      \u003cimg src=\"/gifs/surjective/surjective.gif\" alt=\"Surjective\" style=\"width:100%; height:auto;\"\u003e\n      \u003cdiv\u003e\u003cstrong\u003e(a) Surjective but not Injective\u003c/strong\u003e\u003c/div\u003e\n      \u003cdiv style=\"font-size:0.9em; color:gray;\"\u003eThe output covers the whole space, while self-crossing\u003c/div\u003e\n    \u003c/td\u003e\n    \u003ctd style=\"width:33%; vertical-align:top;\"\u003e\n      \u003cimg src=\"/gifs/surjective/injective.gif\" alt=\"Injective\" style=\"width:100%; height:auto;\"\u003e\n      \u003cdiv\u003e\u003cstrong\u003e(b) Injective but not Surjective\u003c/strong\u003e\u003c/div\u003e\n      \u003cdiv style=\"font-size:0.9em; color:gray;\"\u003eDistinct inputs stay distinct, but an output region is not reached.\u003c/div\u003e\n    \u003c/td\u003e\n    \u003ctd style=\"width:33%; vertical-align:top;\"\u003e\n      \u003cimg src=\"/gifs/surjective/bijective.gif\" alt=\"Bijective\" style=\"width:100%; height:auto;\"\u003e\n      \u003cdiv\u003e\u003cstrong\u003e(c) Bijective\u003c/strong\u003e\u003c/div\u003e\n      \u003cdiv style=\"font-size:0.9em; color:gray;\"\u003eEvery vector in the output space has corresponding input(s) \u003c/div\u003e\n    \u003c/td\u003e\n  \u003c/tr\u003e\n\u003c/table\u003e\n\u003ch2 id=\"ok-cool-but-what-do-they-mean-for-generative-models-like-llms\"\u003eOK cool! But what do they mean for generative models like LLMs?\u003c/h2\u003e\n\u003cp\u003eWe treat a generative model as a function $f$, where the input $x$ is the input we feed to the model, and output $y$ is the content the model generates. For now we do not specify what $\\mathcal{X},\\mathcal{Y}$ are exactly. Let us just think of them as input prompts and model responses for the moment and see what would happen if certain properties of $f$ were true.\u003c/p\u003e\n\u003ch5 id=\"when-f-is-surjective\"\u003eWhen $f$ is surjective\u0026hellip;\u003c/h5\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003e$f$ is surjective means that jailbreaks are unavoidable in principle\u003c/strong\u003e because for any harmful output, there exists a corresponding input to the output, that jailbreaks the model.\u003c/li\u003e\n\u003cli\u003eThe other direction is not correct. \u003cstrong\u003eA generative model that can be jailbroken is not necessarily surjective\u003c/strong\u003e. It can be the case that $f$ is not surjective but a harmful output falls in the range of $f$.\u003c/li\u003e\n\u003cli\u003eOne may argue that an identity function $f(x)=x$ is surjective, but not harmful. In the LLM world, we can start the conversation with \u0026lsquo;Repeat the following sentences:\u0026rsquo; to realize such function, given that the model is good at instruction following. One may further argue that the input corresponding to harmful outputs can be hard to find anyways. Indeed, surjectivity does not capture the capability of generative models, or how hard it is to find a corresponding input, and hence \u003cstrong\u003esurjectivity alone does not imply that the model is unsafe in general\u003c/strong\u003e. However, studying surjectivity is still a good starting point for safety. After all, we need to first ask whether jailbreaks are possible, and then ask whether jailbreaks are tractable.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eWhen the generative model has physical consequences, surjectivity alone is already scary.\u003c/strong\u003e A lot of robotics applications have started to use generative models due to their extraordinary capability. Let us say $\\mathcal{X}$ is the visual inputs to a humanoid robot, and $\\mathcal{Y}$ is the robot actions. A surjective policy $f$ would mean that there exists a video clip, such that when it is played to the robot, the robot goes to kill a person!\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch5 id=\"when-f-is-injective\"\u003eWhen $f$ is injective\u0026hellip;\u003c/h5\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003e$f$ is injective means that it is possible to find out the input from the output in principle, and is hence vulnerable to privacy disclosure\u003c/strong\u003e because no two inputs produce the same output.\u003c/li\u003e\n\u003cli\u003eAnother interpretation of injectivity is that \u003cstrong\u003e$f$ is a lossless compression of the input.\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003eJust like surjectivity, injectivity does not capture how hard it is to find a corresponding input. \u003cstrong\u003eHence injectivity alone does not guarantee that we could recover input from the output.\u003c/strong\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eAs stated above, both surjectivity and injectivity are mere existential properties. Proving that a function is surjective/injective does not necessarily provide us with an easy way of finding the corresponding inputs. However, the connection between these properties and real-world risks is \u003cstrong\u003enot\u003c/strong\u003e symmetric. \u003cstrong\u003eA safety violation\u003c/strong\u003e occurs when a harmful output \u003cstrong\u003ecan be produced\u003c/strong\u003e — that is, when such an output lies in the model’s range. This connects \u003cem\u003edirectly\u003c/em\u003e to surjectivity: if the model is surjective onto the harmful set, then by definition, every harmful output can be generated. The existence itself already signals potential danger. \u003cstrong\u003eA privacy violation\u003c/strong\u003e, on the other hand, happens when private information \u003cstrong\u003ecan be recovered\u003c/strong\u003e from the output, so whether we could find out the information is, by definition, important. Injectivity only says that each output corresponds to a unique input, but it does \u003cem\u003enot\u003c/em\u003e tell us that this input can be feasibly reconstructed. The secret may remain safe even if the mapping is injective, as long as inversion is computationally or statistically hard. In short,  \u003cstrong\u003esurjectivity points to an immediate safety concern, whereas injectivity still depends on whether the inversion is actually achievable.\u003c/strong\u003e\u003c/p\u003e\n\u003ch2 id=\"so-are-llms-surjectiveinjectiveinvertible\"\u003eSo, Are LLMs Surjective/Injective/Invertible?\u003c/h2\u003e\n\u003cp\u003eNow we look into the claims in [1] and [2] and see what can be said about Transformers. Transformers are sequence models, i.e. they input sequence of vectors $a_1,\\dots,a_n$, and outputs sequence $b_1,\\dots,b_n=\\text{TF}(a_1,\\dots,a_n)$. Here $a_1,\\dots,a_n,b_1,\\dots,b_n\\in\\mathbb{R}^d$ are all vectors of the same dimension. In language models, every element of the input token sequence $s_1,\\dots,s_n\\in\\mathcal{V}$ comes from a finite vocabulary set $\\mathcal{V}$. We first turn \u003cem\u003ediscrete\u003c/em\u003e tokens into \u003cem\u003econtinuous\u003c/em\u003e embeddings via a function $a_i=\\text{Embed}(s_i)$ before passing it to $\\text{TF}$. Similarly, we also turn \u003cem\u003econtinuous\u003c/em\u003e embeddings to \u003cem\u003ediscrete\u003c/em\u003e tokens via another function $t_i=\\text{Unembed}(b_i)$ before outputting.\u003c/p\u003e\n\u003cp\u003eNowadays decoder-only Transformers like GPT decode iteratively in an \u003cem\u003eautoregressive\u003c/em\u003e manner. We start from a prompt $s_1,\\dots,s_n$. In each iteration we calculate $b_1,\\dots,b_i=\\text{TF}(a_1,\\dots,a_i)$ from the already generated content $s_1,\\dots,s_i$, decode the next token as $s_{i+1}=\\text{Unembed}(b_i)$ and append it to the end of the existing content. The generation ends when we generate a special token $s_n=\\texttt{EOS}$.\u003c/p\u003e\n\u003ch5 id=\"on-surjectivity-of-neural-networks-1\"\u003eOn Surjectivity of Neural Networks ([1])\u003c/h5\u003e\n\u003cp\u003eThis paper proves that \u003cstrong\u003e$\\text{TF}$ is a surjective function\u003c/strong\u003e, no matter what the parameters are. However it does \u003cstrong\u003enot\u003c/strong\u003e prove that LLMs are surjective for the following two reasons:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eThis paper works in the continuous space, while the language models work in the discrete space.\u003c/li\u003e\n\u003cli\u003eThis paper does not work with autoregressive generation.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eThis conclusion sounds reassuring for language models. However, \u003cstrong\u003ethe paper proves surjectivity results for broader popular generative model architectures\u003c/strong\u003e, such as \u003cem\u003ediffusion models\u003c/em\u003e and \u003cem\u003erobotics models\u003c/em\u003e. For these applications discretization and autoregressiveness do not exist, and hence the safety threats are more serious. One may refer to Section 4 of the paper for more discussions.\u003c/p\u003e\n\u003ch5 id=\"language-models-are-injective-and-hence-invertible-2\"\u003eLanguage Models are Injective and Hence Invertible ([2])\u003c/h5\u003e\n\u003cp\u003e\u003cstrong\u003eThis paper analyzes a different function from the last one.\u003c/strong\u003e  It proves that \u003cstrong\u003ethe function from $s_1,\\dots,s_n$, the input \u003cem\u003etoken sequence\u003c/em\u003e, to $b_n$, the output \u003cem\u003eembedding\u003c/em\u003e, is injective\u003c/strong\u003e, excluding a negligible subset of $\\text{TF}$\u0026rsquo;s parameter space. However, it does \u003cstrong\u003enot\u003c/strong\u003e prove that LLMs are injective from input sequences to output sequences, as different embeddings can lead to the same token.\u003c/p\u003e\n\u003cp\u003eMoreover, the function from input token sequence to output embedding is \u003cstrong\u003enot\u003c/strong\u003e surjective. This is because the set of input sequences is discrete and the set of output embeddings is continuous, and no continuous function with discrete inputs can be surjective on a continuous output. \u003cstrong\u003eHence this function is not invertible.\u003c/strong\u003e The word invertible in the title is \u003cstrong\u003enot\u003c/strong\u003e used in a conventional way, and just mean that it is possible to invert an already generated output back to input.\u003c/p\u003e\n\u003cp\u003eLet us now compare these two settings in a minimal setting. Let\u0026rsquo;s say the input is just a single token $s_1\\in\\mathcal{V}={\\text{one},\\text{day},\\text{egg}}$, it is transformed into a 2-dimensional embedding $a_1$. The output $b_1=\\text{TF}(a_1)$ is also two dimensional. According to [1] the function from $a_1$ to $b_1$ is surjective, and according to [2] the function from $s_1$ to $b_1$ is injective. The $\\text{TF}$ transformation looks like the following:\u003c/p\u003e\n\u003ctable style=\"width:100%; table-layout:fixed; text-align:center;\"\u003e\n  \u003ctr\u003e\n    \u003ctd style=\"width:33%; vertical-align:top;\"\u003e\n      \u003cimg src=\"/gifs/surjective/surjective.gif\" alt=\"Surjective\" style=\"width:100%; height:auto;\"\u003e\n      \u003cdiv\u003e\u003cstrong\u003e(a) Continuous to Continuous\u003c/strong\u003e\u003c/div\u003e\n      \u003cdiv style=\"font-size:0.9em; color:gray;\"\u003eThe output covers the whole space, while self-crossing.\u003c/div\u003e\n    \u003c/td\u003e\n    \u003ctd style=\"width:33%; vertical-align:top;\"\u003e\n      \u003cimg src=\"/gifs/surjective/contrast.gif\" alt=\"Injective\" style=\"width:100%; height:auto;\"\u003e\n      \u003cdiv\u003e\u003cstrong\u003e(b) Contrast\u003c/strong\u003e\u003c/div\u003e\n      \u003cdiv style=\"font-size:0.9em; color:gray;\"\u003eThe continuous function is surjective, while the discrete function is injective.\u003c/div\u003e\n    \u003c/td\u003e\n    \u003ctd style=\"width:33%; vertical-align:top;\"\u003e\n      \u003cimg src=\"/gifs/surjective/discrete.gif\" alt=\"Bijective\" style=\"width:100%; height:auto;\"\u003e\n      \u003cdiv\u003e\u003cstrong\u003e(c) Discrete to Continuous\u003c/strong\u003e\u003c/div\u003e\n      \u003cdiv style=\"font-size:0.9em; color:gray;\"\u003eDifferent embeddings do not collide.\u003c/div\u003e\n    \u003c/td\u003e\n  \u003c/tr\u003e\n\u003c/table\u003e\n\u003cp\u003eFrom this figure, the fact that \u003cstrong\u003ea map from a discrete set to a continuous set is very likely injective\u003c/strong\u003e should be intuitive. The rigorous proof is presented [1]. The surjectivity between two continuous spaces, however, is a lot trickier, and I will write another blog dedicated to explaining the intuitions and proofs. Furthermore, \u003cstrong\u003eboth papers provide similar algorithms to recover $a_1,\\dots,a_n$ from $b_1,\\dots,b_n$ given the parameters in $\\text{TF}$\u003c/strong\u003e, and the inputs turn out to be very easy to recover in this setting. However, this setting is far from useful and how to recover $s_1,\\dots,s_n$ from $b_n$ remains elusive.\u003c/p\u003e\n\u003ch2 id=\"concluding-remarks\"\u003eConcluding Remarks\u003c/h2\u003e\n\u003cp\u003eAfter reading this blog, it should be clear that \u003cstrong\u003eLLMs are neither surjective nor injective from input sequences to output sequences\u003c/strong\u003e. Though surjectivity has safety implications and injectivity has privacy implications, these threats has \u003cstrong\u003enot\u003c/strong\u003e reached the realm of LLMs yet. The seemingly contradicting claims from the two papers stem from the fact that they are considering different functions. More broadly, surjectivity/injectivity could imply safety/privacy risks in domains where continuous inputs/outputs are present.\u003c/p\u003e\n\u003ch2 id=\"reference\"\u003eReference\u003c/h2\u003e\n\u003cp\u003e[1] Haozhe Jiang and Nika Haghtalab. On surjectivity of neural networks: Can you elicit any behavior from your model? \u003cem\u003earXiv preprint arXiv:2508.19445\u003c/em\u003e, 2025.\u003c/p\u003e\n\u003cp\u003e[2] Giorgos Nikolaou, Tommaso Mencattini, Donato Crisostomi, Andrea Santilli, Yannis Panagakis and Emanuele Rodolà. Language Models are Injective and Hence Invertible \u003cem\u003earXiv preprint arXiv:2510.15511\u003c/em\u003e, 2025.\u003c/p\u003e\n","description":"Blog","image":"/gifs/surjective/surjective.gif","permalink":"/blogs/surjective/","title":"Can Transformers Do Everything, and Undo It Too?"},{"content":"","description":"","image":"/images/Hangzhou/DSC04362.jpg","permalink":"/gallery/hangzhou/","title":"Hangzhou"},{"content":"","description":"","image":"/images/Hawaii/DSC03619.jpg","permalink":"/gallery/hawaii/","title":"Hawaii"},{"content":"","description":"","image":"/images/Princeton/DSC04800.jpg","permalink":"/gallery/princeton/","title":"Princeton"},{"content":"","description":"","image":"/images/Rwanda/DSC02402.jpg","permalink":"/gallery/rwanda/","title":"Rwanda"},{"content":"","description":"","image":"/images/Seattle/DSC02286.jpg","permalink":"/gallery/seattle/","title":"Seattle"},{"content":"","description":"","image":"/images/Shanghai/DSC02062.jpg","permalink":"/gallery/shanghai/","title":"Shanghai"},{"content":"","description":"","image":"/images/Vienna/DSC05648.jpg","permalink":"/gallery/vienna/","title":"Vienna"},{"content":"","description":"","image":"/images/Yili/DSC07636.jpg","permalink":"/gallery/yili/","title":"Yili"},{"content":"\n\u003cdiv class=\"pub-search-index\" style=\"display:none\"\u003e On Surjectivity of Neural Networks: Can you elicit any behavior from your model?  Haozhe Jiang, Nika Haghtalab  Theory Deep Learning  We prove that a lot of practical architures for generative models are surjective, regardless of how they are trained. This means that any output, including undesirable ones, can be elicited by some input, leading to a fundamental vulnerability to jailbreaks.\n \n\n   A Black-box Approach for Non-stationary Multi-agent Reinforcement Learning  Haozhe Jiang, Qiwen Cui, Zhihan Xiong, Maryam Fazel, Simon S Du  Theory Game Theory  ICLR 2024  Can we track Equilibria in non-stationary Multi-agent systems? We comprehensively analyze this problem and find most non-stationary bandit algorithms fail to generalize. In multi-agent systems, **different actions compete with different best responses**. This forbids us from comparing actions by comparing their own rewards, sabotaging all test-based algorithms. We solve this problem by using an Explore-then-Commit-then-Test algorithm, in combination with prior techniques. This black-box algorithm is simple but admits a no-regret guarantee.\n \n\n   Offline Meta Reinforcement Learning with In-Distribution Online Adaptation  Jianhao Wang*, Jin Zhang*, Haozhe Jiang, Junyu Zhang, Liwei Wang, Chongjie Zhang  Reinforcement Learning Meta Learning  ICML 2023  Why is it hard to do offline meta-learning? We point out that the meta-learning setting induces a new type of **distribution shift between offline training and online adaptation**. We characterize this challenge and propose IDAQ, a simple greedy context-based algorithm to tackle this problem.\n \n\n   Practically Solving LPN in High Noise Regimes Faster Using Neural Networks  Haozhe Jiang*, Kaiyue Wen*, Yilei Chen  Theory Cryptography Deep Learning  Can we break the Learning Parity with Noise (LPN) problem with Neural Networks? Empirically, we find out that **when the noise is high, neural networks are particularly useful**. We corroborate this observation by proving that the sample complexity of some neural networks scales optimally with the noise. This is the first neural-network-based algorithm surpassing all classical counterparts in breaking cryptographic primitives.\n \n\n   Offline congestion games: How feedback type affects data coverage requirement  Haozhe Jiang*, Qiwen Cui*, Zhihan Xiong, Maryam Fazel, Simon S Du   Theory Game Theory  ICLR 2023  If we want to learn Nash Equilibrium in congestion games, what offline dataset should we have? By looking at **dataset coverage in facility space** instead of action space, we find out the minimal dataset coverage requirement. We also present efficient learning algorithms and demonstrate the **separation** of coverage requirements under different feedback models.\n \n\n   Offline reinforcement learning with reverse model-based imagination  Jianhao Wang*, Wenzhe Li*, Haozhe Jiang, Guangxiang Zhu, Siyuan Li, Chongjie Zhang  Reinforcement Learning  NeurIPS 2021  You can’t connect the dots looking forward; you can only connect them looking backwards. How to learn RL policy generalizing from offline datasets while avoiding dangerous actions? We propose to **learn a reverse dynamic model** instead of a forward one. If a forward model goes wrong, the learned policy may take dangerous actions. If a reverse model goes wrong, the agent still acts safely because it could not start at the wrong reversed state in the first place.\n \n\n  \u003c/div\u003e\n\n","description":"Research Papers","image":null,"permalink":"/publications/","title":"Publications"}]